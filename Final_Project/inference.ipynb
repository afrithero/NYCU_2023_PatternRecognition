{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EPR16IGJrhFo"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from os.path import join\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZC1XbwErwc7",
        "outputId": "0c8affe6-7b4f-4370-de12-c1c822f0ef1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Note 1: Please specify where the dataset is, the directory structure must be consistent with the content of \"captcha-hacker-2023-spring.zip\".\n",
        "- Note 2: sample_submission.csv is also needed for indicating the label length of testing data in each task. If TAs are going to use the inference code to predict on private set on kaggle, there should be another sample_submission.csv for private set that the format must be the same as the file provided before. Apologize for any inconvenience ><\".\n",
        "- Note 3: Please specify where the model weight is and the location to save the prediction.\n",
        "- Note 4: Please change the run time type to 'GPU'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tucEGgnRrhFq"
      },
      "outputs": [],
      "source": [
        "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "ALPHABET = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', \n",
        "\t\t\t\t\t\t'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\t\t\t\t\t\t\n",
        "ALL_CHAR_SET = NUMBER + ALPHABET\n",
        "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
        "\n",
        "MAX_CAPTCHA = 4\n",
        "\n",
        "CAPTCHA_TO_INDEX_DICT = {char: index for index, char in enumerate(ALL_CHAR_SET)}\n",
        "INDEX_TO_CAPTCHA_DICT = {index: char for index, char in enumerate(ALL_CHAR_SET)}\n",
        "\n",
        "# Note 1\n",
        "dataset_path = '/content/drive/MyDrive/Pattern_Recognition_Final_Project/dataset'\n",
        "\n",
        "# Note 2\n",
        "sample_submission_path = join(dataset_path, 'sample_submission.csv')\n",
        "\n",
        "# Note 3\n",
        "model_weight_path = '/content/drive/MyDrive/Pattern_Recognition_Final_Project/ResNet_34_epoch_50_acc_0.9724.pkl'\n",
        "submission_path = '/content/drive/MyDrive/Pattern_Recognition_Final_Project/submission_ResNet_temp.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bkXXKHaarhFq"
      },
      "outputs": [],
      "source": [
        "class CaptchaDataset(Dataset):\n",
        "\t\tdef __init__(self, dataset_path, df, is_predict=False):\n",
        "\t\t\tself.dataset_path = dataset_path\n",
        "\t\t\tself.data = df[\"filename\"].tolist()\n",
        "\t\t\traw_labels = df[\"label\"].tolist()\n",
        "\t\t\tself.is_predict = is_predict\n",
        "\t\t\tif is_predict:\n",
        "\t\t\t\tself.labels = np.array(raw_labels)\n",
        "\t\t\t\n",
        "\t\tdef __getitem__(self, index):\n",
        "\t\t\tfile_name, label = self.data[index], self.labels[index]\n",
        "\t\t\tif self.is_predict:\n",
        "\t\t\t\timg = cv2.imread(join(self.dataset_path, \"test\", file_name),  cv2.IMREAD_GRAYSCALE)\n",
        "\t\t\timg = img.reshape(img.shape[0],img.shape[1], -1)\n",
        "\t\t\timg = (img - 128) / 128\n",
        "\t\t\timg = np.transpose(img,(2,0,1)) #因為 Conv2D channel 要在第一個 dim，所以做轉換\n",
        "\t\t\treturn torch.tensor(img,dtype=torch.float), torch.tensor(label, dtype=torch.float), file_name\n",
        "\t\t\t\n",
        "\t\tdef __len__(self):\n",
        "\t\t\treturn len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "biKsGwUjrhFr"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "\t\tdef __init__(self, inchannel, outchannel, stride=1):\n",
        "\t\t\t\tsuper(ResidualBlock, self).__init__()\n",
        "\t\t\t\tself.left = nn.Sequential(\n",
        "\t\t\t\t\t\tnn.Conv2d(inchannel,\n",
        "\t\t\t\t\t\t\t\t\t\t\toutchannel,\n",
        "\t\t\t\t\t\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\t\t\t\t\t\tstride=stride,\n",
        "\t\t\t\t\t\t\t\t\t\t\tpadding=1,\n",
        "\t\t\t\t\t\t\t\t\t\t\tbias=False),\n",
        "\t\t\t\t\t\tnn.BatchNorm2d(outchannel, track_running_stats=True),\n",
        "\t\t\t\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\t\t\t\tnn.Conv2d(outchannel,\n",
        "\t\t\t\t\t\t\t\t\t\t\toutchannel,\n",
        "\t\t\t\t\t\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\t\t\t\t\t\tstride=1,\n",
        "\t\t\t\t\t\t\t\t\t\t\tpadding=1,\n",
        "\t\t\t\t\t\t\t\t\t\t\tbias=False),\n",
        "\t\t\t\t\t\tnn.BatchNorm2d(outchannel, track_running_stats=True))\n",
        "\n",
        "\t\t\t\tself.shortcut = nn.Sequential()\n",
        "\n",
        "\t\t\t\tif stride != 1 or inchannel != outchannel:\n",
        "\t\t\t\t\t\tself.shortcut = nn.Sequential(\n",
        "\t\t\t\t\t\t\t\tnn.Conv2d(inchannel,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\toutchannel,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tkernel_size=1,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tstride=stride,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tbias=False),\n",
        "\t\t\t\t\t\t\t\tnn.BatchNorm2d(outchannel, track_running_stats=True),\n",
        "\t\t\t\t\t\t\t\tnn.ReLU())\n",
        "\n",
        "\t\tdef forward(self, x):\n",
        "\t\t\t\tout = self.left(x)\n",
        "\t\t\t\tout += self.shortcut(x)\n",
        "\t\t\t\t# out = F.relu(out)\n",
        "\t\t\t\treturn out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\t\tdef __init__(self, ResidualBlock, num_classes=62):\n",
        "\t\t\t\tsuper(ResNet, self).__init__()\n",
        "\t\t\t\tself.inchannel = 64\n",
        "\t\t\t\tself.conv1 = nn.Sequential(\n",
        "\t\t\t\t\t\tnn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\t\t\t\tnn.BatchNorm2d(64, track_running_stats=True),\n",
        "\t\t\t\t\t\tnn.ReLU(),\n",
        "\t\t\t\t)\n",
        "\t\t\t\t# ResidualBlock basic\n",
        "\t\t\t\t# res34 3 4 6 3\n",
        "\t\t\t\tself.layer1 = self.make_layer(ResidualBlock, 64, 3, stride=1)\n",
        "\t\t\t\tself.layer2 = self.make_layer(ResidualBlock, 128, 4, stride=2)\n",
        "\t\t\t\tself.layer3 = self.make_layer(ResidualBlock, 256, 6, stride=2)\n",
        "\t\t\t\tself.layer4 = self.make_layer(ResidualBlock, 512, 3, stride=2)\n",
        "\t\t\t\tself.drop = nn.Dropout(0.5)\n",
        "\t\t\t\tself.rfc = nn.Sequential(\n",
        "\t\t\t\t\tnn.Linear(512, MAX_CAPTCHA*ALL_CHAR_SET_LEN),\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\tdef make_layer(self, block, channels, num_blocks, stride):\n",
        "\t\t\t\tstrides = [stride] + [1] * (num_blocks - 1)  # strides = [1,1]\n",
        "\t\t\t\tlayers = []\n",
        "\t\t\t\tfor stride in strides:\n",
        "\t\t\t\t\t\tlayers.append(block(self.inchannel, channels, stride))\n",
        "\t\t\t\t\t\tself.inchannel = channels\n",
        "\t\t\t\treturn nn.Sequential(*layers)\n",
        "\n",
        "\t\tdef forward(self, x):\n",
        "\t\t\t\tx = self.conv1(x)\n",
        "\t\t\t\t# 100, 64, 96, 96\n",
        "\t\t\t\tx = self.layer1(x)\n",
        "\t\t\t\t# 100, 64, 96, 96\n",
        "\t\t\t\tx = self.layer2(x)\n",
        "\t\t\t\t# 100, 128, 48, 48\n",
        "\t\t\t\tx = self.layer3(x)\n",
        "\t\t\t\t# 100, 256, 24, 24\n",
        "\t\t\t\tx = self.layer4(x)\n",
        "\t\t\t\t# 100, 512, 12, 1\n",
        "\t\t\t\tx = nn.AdaptiveAvgPool2d(1)(x)\n",
        "\t\t\t\t# 100, 512, 1, 1\n",
        "\t\t\t\tx = x.view(-1, 512)\n",
        "\t\t\t\t# 100, 512\n",
        "\t\t\t\tx = self.drop(x)\n",
        "\t\t\t\tx = self.rfc(x)\n",
        "\t\t\t\t# 100, 248\n",
        "\t\t\t\treturn x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WeTfBqYkrhFs"
      },
      "outputs": [],
      "source": [
        "def parse_submission(sample_submission_path):\n",
        "\tdef assign_label_len(x):\n",
        "\t\tif x.startswith('task1'):\n",
        "\t\t\t\treturn 1\n",
        "\t\telif x.startswith('task2'):\n",
        "\t\t\t\treturn 2\n",
        "\t\telse:\n",
        "\t\t\t\treturn 4\n",
        "\tdf = pd.read_csv(sample_submission_path)\n",
        "\tdf['label'] = df['filename'].apply(assign_label_len)\n",
        "\t\n",
        "\treturn df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zvyFZxiprhFs"
      },
      "outputs": [],
      "source": [
        "def predict(model, data_loader, df):\n",
        "\tmodel.eval()\n",
        "\tmodel.load_state_dict(torch.load(model_weight_path))\n",
        "\tbatches = tqdm(data_loader, total=len(data_loader), leave=False)\n",
        "\tpreds = []\n",
        "\n",
        "\tfor image, label, file_name in batches:\n",
        "\t\timage = image.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\t\tpred = model(image)\n",
        "\t\tif label.item() == 1.0:\n",
        "\t\t\ttext_0 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, 0:ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\tpred_decoded = f'{text_0}'\n",
        "\t\telif label.item() == 2.0:\n",
        "\t\t\ttext_0 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, 0:ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\ttext_1 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, ALL_CHAR_SET_LEN:2*ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\tpred_decoded = f'{text_0}{text_1}'\n",
        "\t\telif label.item() == 4.0:\n",
        "\t\t\ttext_0 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, 0:ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\ttext_1 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, ALL_CHAR_SET_LEN:2*ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\ttext_2 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, 2*ALL_CHAR_SET_LEN:3*ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\ttext_3 = INDEX_TO_CAPTCHA_DICT[np.argmax(pred[0, 3*ALL_CHAR_SET_LEN:4*ALL_CHAR_SET_LEN].data.cpu().numpy())]\n",
        "\t\t\tpred_decoded = f'{text_0}{text_1}{text_2}{text_3}'\n",
        "\t\t\n",
        "\t\tpreds.append(pred_decoded)\n",
        "\t\tbatches.set_description(f'[label_length:{label.item()}/Pred:{pred_decoded}]')\n",
        "\t\tbatches.set_postfix(file = file_name)\n",
        "\n",
        "\tdf['label'] = preds\n",
        "\t\n",
        "\tdf.to_csv(submission_path,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMV5-V4SrhFt",
        "outputId": "c0f02f60-ab2b-4902-ad65-7a830ba311b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "\tdf_test = parse_submission(sample_submission_path)\n",
        "\ttest_ds = CaptchaDataset(dataset_path, df_test, is_predict=True)\n",
        "\ttest_dl = DataLoader(test_ds, batch_size=1, num_workers=2, drop_last=True, shuffle=False)\n",
        "\tmodel = ResNet(ResidualBlock)\n",
        "\tmodel.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\tpredict(model, test_dl, df_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
